---
title: "Workflow: SentiAnalyzer"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{SentiAnalyzer}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

### Sentiment analysis for consumer review

SentiAnalyzer is a "one-stop" solution for analysis of of consumer reviews which includes natural language processing (NLP) of consumer sentiments. The dataset that SentiAnalyzer can work with for now is short text and a binary quantification, e.g. whether consumer hits the like button. The NLP of the sentiment is analyzed through the options of algorithms to compile the words and the machinge learning training model of choice.  

## Installation
`install.packages("SentiAnalyzer")`

## Usage

Major steps of processing your textual dataset: 

1. Balancing the dataset

2. Streamlining the text to get a sense of the major keywords

3. Train different classification algorithms(e.g., SVM,NB,RF,KNN,GBM) and choose best parameters for each one to get the highest possible classification accuracy for an specefic dataset

3. Choose the best trained classification algorithm for the specific dataset according to different measures (e.g., FScore, Recall, Precision, Accuracy) 

5. Visualize the output of the confusion matrix, that is, the accuracy of the training model in predicting the sentiment of the consumer review

## Tackling imbalanced data
The first step to process your data is to make sure that both of your variables have equal numbers of observations/unit. `BalanceData` function can be used to balance the called dataset. Using packages: `ROSE`, balance the columns of the data. For oversampled data, used `ovun.sample` to balance over or under sampled data. Then check the balance of the columns/variables.

#### Importing the imbalance dataset (OPTIONAL)
```{r include=FALSE}
imb <- system.file(package = "SentiAnalyzer", "extdata/Imbalance_Restaurant_Reviews.tsv")
imbalance_data <- read.delim(imb,quote='',stringsAsFactors = FALSE)
```

```{r message=FALSE, include=TRUE, warning=FALSE, results='hold'}
head(imbalance_data)
```

```{r message=FALSE, include=TRUE, warning=FALSE, results='hide', echo=TRUE}
SentiAnalyzer::BalanceData(imbalance_data)
```

check the balanced dataset, same number of rows and columns now

```{r include=FALSE}
direction <- system.file(package = "SentiAnalyzer", "extdata/Restaurant_Reviews.tsv")
balanced_data <- read.delim(direction,quote='',stringsAsFactors = FALSE)
```

```{r message=FALSE, include=TRUE, warning=FALSE, results='hold' }
dim(balanced_data)
str(balanced_data)
```


## Early Visualization
Before we start any further major processing of data, we can quickly get an insight of the data through a word cloud visualization. Termcount is used for filtering the highest terms repeated in reviews, usually > 10 count

check out [shiny version of this function](https://joeybudi.shinyapps.io/zahra/)

**input**: a balanced dataset of text and binary sentiment review, low baseline for term count 

**output**: wordcloud plot and frequency of words bar plot
```{r message=FALSE, include=TRUE, warning=FALSE, results='hold', echo=TRUE, eval=TRUE}
SentiAnalyzer::VisualizeData(balanced_data,12)
```


## Cleaning the text
**input**: `CleanText()` calls for 3 arguments: 

a. the dataset 
b. document term matrix structure of choice (choose 1 from 3) 
c. reduction rate (range 0-1)

**output**: `CleanText()` returns a matrix `clean_dataset` saved as `data/clean_dataset.rda`

packages used: `tm` and `SnowballC`

##### a. text-mining the dataset
integrating built-in functions from `tm`, `CleanText()` will "clean up" the words from the text and mine for the words that conveys a range sorts of sentiment and convert some formatting; this remains what is called as token (single) or corpus (all the tokens):

a. converts all text to lower case
b. remove numbers from the text
c. remove punctuations
d. remove stop words, e.g. "the", "a", "for", "and", etc
e. extract the stems of thegiven words using Porter's stemming algorithmn
f. remove extra white spaces that was left off by the removed texts 
```{r message=FALSE, include=TRUE, warning=FALSE, results='hide', echo=TRUE}
library(tm)
```

```{r message=FALSE, include=TRUE, warning=FALSE, results='hold', echo=FALSE}
corpus=VCorpus(VectorSource(balanced_data$Review)) 
corpus=tm_map(corpus,content_transformer(tolower)) #convert all review to lower case
corpus=tm_map(corpus,removeNumbers) # remove numbers from reviews
corpus=tm_map(corpus,removePunctuation) # remove punctuations from reviews
corpus=tm_map(corpus,removeWords,stopwords()) # remove Stop words from reviews
corpus=tm_map(corpus,stemDocument) # Stemming
corpus=tm_map(corpus,stripWhitespace) # remove extra space that's created in cleaning stage above
```
```{r message=FALSE, include=TRUE, warning=FALSE, results='hold', echo=FALSE}
corpus$content[[1]][[1]]
corpus$content[[2]][[1]]
corpus$content[[3]][[1]]
corpus$content[[4]][[1]]
corpus$content[[5]][[1]]
corpus$content[[6]][[1]]
```
##### b. Creating the document-term matrix/bag of words model
Next, still within the scope of the same current function, `Cleantext()`, the corpus is formatted to a [document-term matrix](#https://en.wikipedia.org/wiki/Document-term_matrix) (DTM) and creating document term matrix of words in reviews. Essentially it creates a single column for every tokens in the corpus and counted for frequency of occurence on each tokens on the rows

user also have the choice to choose either (the argument call is also done on `CleanText`):

1. bag of words
2. tf-idf (term frequency-inverse document frequency)
3. Bi-gram 

##### c. choosing the reduction rate
the document-term matrix will quickly expand the dataset dimension, especially the sparse terms, significantly. Depending on the dimension of the dataset can be adjusted be adjusted within the range 0 to 1. Essentially it is calling `tm::removeSparseTerms`
```{r message=FALSE, include=TRUE, warning=FALSE, results='hide', echo=TRUE}
clean_dataset <- SentiAnalyzer::CleanText(balanced_data, dtm_method=1, reductionrate=0.99)
```
example:
```{r message=FALSE, include=TRUE, warning=FALSE, results='hold', echo=FALSE}
dim(clean_dataset)
names(clean_dataset)[1:50]
head(clean_dataset[1:10])
tail(clean_dataset[1:10])
```


## Building  classification training
Train different classification algorithms and choose best parameters for each one to get the highest possible classification accuracy for an specefic dataset. The algorithms that we can choose from that is available in the package are:

a. Gradient-boosting machine (GBM)
b. k-Nearest Neighbor (KNN)
c. Naive Bayes (NB)
d. Random Forest (RF)
e. svm_Poly

**input**: document-term matrix (result from `CleanText()` which is `clean_dataset`)

**output**: list of trained models with best parameters from 5 machine learning algorithms (GBM, KNN, NB, RF,SVM_Poly)

**Using cross validation for a valid testing accuracy**

using package `caret`, and `traincontrol`

Using the whole dataset for training purpose and 10-fold cross validation for a valid estimate of testing accuracy.

### Example training classifier : KNN
The model training consist of `expand.grid()`, `train()` (formula, data, method, train control, tuneGrid, etc)

**Training KNN with the best parameters using `caret` traning function.** (warning, this function will take a lot of time to run, so we are showing a reduced version of it)
```{r message=FALSE, include=FALSE, warning=FALSE, echo=TRUE, eval=FALSE}
SentiAnalyzer::BuildTraining(clean_dataset)
```

```{r message=FALSE, include=TRUE, warning=FALSE, results='hide', echo=FALSE, eval=TRUE}
#csv_data <- read.csv(system.file(package = "SentiAnalyzer", "extdata/testing1.csv"))
data(package = "SentiAnalyzer", testing1)
res_name <- colnames(testing1)[ncol(testing1)]
  formula <- as.formula(paste(res_name, ' ~ .'))
  
  if (is.factor(testing1[, ncol(testing1)]) == FALSE) {
    testing1[, ncol(testing1)] <- ifelse(testing1[, ncol(testing1)] == 1, "Yes", "No")
    testing1[, ncol(testing1)] <- factor(testing1[, ncol(testing1)], levels = c("Yes", "No"))
    } else {
    testing1[, ncol(testing1)] <- ifelse(testing1[, ncol(testing1)] == 1, "Yes", "No")
  }
    # train control
  ctrl_cv10 = caret::trainControl(
    method = "cv",
    number = 10,
    savePred = T,
    classProb = T
  )
  treeGrid_knn = expand.grid(k = c(1:80))
  ###### kNN with Cross Validation ############
  model_knn_10 =caret::train(
    formula,
    data = testing1,
    method = "knn",
    trControl = ctrl_cv10,
    tuneGrid = treeGrid_knn
  )
```

the list output order of the trained models are: GBM, kNN, Naive Bayes, Decision Tree, svm_Poly. The performance of the trained models can be viewed/visualized by calling a specific model according to the index in the list; `plot()`, which is an  embedded function from `caret`. 
For example, to plot kNN model, 2nd in the list: 
```{r echo=TRUE, eval=FALSE}
plot((BuildTraining(cleandataset)[3])
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
plot(model_knn_10)
```

As shown in plot above it explores up to 100 neighbours for KNN algorithm and selects the best one for the trained KNN model

Another example, output from the  trained Gradient Boosting Machine trained model 
```{r message=FALSE, warning=FALSE, echo=TRUE, eval=FALSE}
BuildTraining(cleandataset)[2]
```

```{r message=FALSE, include=TRUE, warning=FALSE, results='hold', echo=FALSE, eval=FALSE}
data(package = "SentiAnalyzer", "trained_models.rda"))
trained_models[2]
```


## Build Prediction
classifies the target value of input data using different trained algorithms (output of `BuildTraining` function) and return a list of confusion matrices which can have many purposes down the line. We intend to  extract different parameters of the prediction model down the line using `comparison()`. User can also put document-term matrix as input. and this function, depending upon the type of the input, this function will automatically run `BuildTraining()` function if needed. 

**input**: document-term matrix (result from `CleanText()` which is `cleaned_dataset`) or list of trained models (your output of `SentiAnalyzer::BuildTraining()`)

**output**: list of various parameter values of 5 machine learning algorithms (GBM, KNN, NB, RF,SVM_Poly)
Here we used `BuilPrediction` for an already trained object that we load earlier (`trained_models`). As mentioned earlier the input can also be a cleaned document-term matrix (output of `CleanText()` function)

```{r message=FALSE, include=TRUE, warning=FALSE, results='hold', echo=TRUE, eval=FALSE}
df_predicted <- SentiAnalyzer::BuildPrediction(trained_models)
```

## Comparison of ML training models
This function extracts F1, Recall,Precision and Accuracy from confusion matrices list and returns a dataframe of those measurments.

**input**: depending upon the type of the input, function runs appropriate needed functions. Input can be a document-term matrix (result from `CleanText()` which is `cleaned_dataset`) or a list (output of `BuildPrediction` function)
  
**output**: list of confusion matrices of 5 machine learning algorithms
```{r message=FALSE, include=FALSE, warning=FALSE, results='hold', echo=TRUE, eval=FALSE}
Cmx <- SentiAnalyzer::comparison(df_predicted)

```

### Next steps 
what now? How about we visualize these numbers to aid our interpretation of comparing the parameters?

For a more interactive version of the functions, access our [Shiny apps](https://zahrakhoshmanesh.github.io/SentiAnalyzer/articles/shiny.html)

Here is an example of plotly heat map and table of the confusion matrices


**input**: confusion matrix from `Comparison`

**output**: interactive plotly heat map and table
```{r message=FALSE, include=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}
# Cmx_4param <- Cmx[1:4]
# Cmx_4param <- as.data.frame(Cmx_4param)
# #colnames(Cmx_4param) <- c("accuracy","precision","recall","f1-score")
# rownames(Cmx_4param) <- c("Gradient-Boosting", "k-Nearest Neighbors", "Naive Bayes", "Random Forest","SVM")
# 
# 
# 
# #heatmap encompassing 5 ML trained model output, 5 parameters of the confusion matrix
# plotly::plot_ly(z=data.matrix(Cmx_4param),
#                 x=colnames(Cmx_4param),
#                 y=rownames(Cmx_4param),
#                 type="heatmap",
#                 textfont=list(size=20,color = "black"))
# 
# #plotly table for 5 ML trained model output, 5 parameters of the confusion matrix
# plotly::plot_ly(
#   type = 'table',
#   header = list(
#     values = c('<b>Confusion Matrix</b>', rownames(Cmx_4param)),
#     line = list(color = '#506784'),
#     fill = list(color = '#119DFF'),
#     align = c('left','center'),
#     font = list(color = 'white', size = 12)
#   ),
#   cells = list(
#     values = rbind(colnames(Cmx_4param),
#                    data.matrix(Cmx_4param)),
#     line = list(color = '#506784'),
#     fill = list(color = c('#25FEFD', 'white')),
#     align = c('left', 'left'),
#     font = list(color = c('#black'), size = 12)
# 
# 
#   ))

```